{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"83b297e1-8e5b-4d92-8183-97c0522e1f53","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"l7jMHALvxC1_"},"source":["# 2.3. Get Your Data Machine Learning Ready for Classification: Data Wrangling"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4adf9716-1137-440f-ab41-b86663d73ce8","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"dqDW7-9DxC2A"},"source":["## Preparing the Data"]},{"cell_type":"markdown","metadata":{"id":"BcvdqhTYxC2A"},"source":["### **Table of Contents**  \n","\n","- [1. Data Import](#1)  \n","- [2. Data Wangling](#2)\n","  - [2.1 Response Variable Distribution](#21)\n","  - [2.2 Rare Classes in Features](#22)\n","  - [2.3 Noninformative features](#23)\n","- [3. Data Splitting](#3)\n","  - [3.1 Full Data to Training and Testing](#31)\n","  - [3.2 Training to Build and Validation](#32)\n","- [4. Addressing Class Imbalance](#4)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"65735c6b-a338-44ac-ad41-becd2d380343","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"asnlabDMxC2A"},"source":["<a id=\"1\"></a>\n","## 1 Data Import"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b68074fe-7f6d-4ca1-99a2-2f1c0f54129c","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"B-lDaDLsxC2A"},"source":["In Course 1, Module 3: *Magic Pandas Library: Mastering Higher Education Data Preparation and Analysis*, we learned how to merge data that originated from multiple sources accross campus. The High School, Enrollment, Admissions, Course and Completion datasets all provide valuable information to assist us in our effort to predict student metrics in future semesters. As you recall, we've selected a subset of the variables from these data to include in the modeling phase. These include:\n","1. Academic Performance Data\n","\n","      - Available at time of admission: high school GPAs\n","\n","      - Available at time of modeling: units attempted, completed and DFW, and available postsecondary GPAs  \n","2. Demographic Data\n","      - Gender, ethnicity, first gen status\n","\n","3. The target variable, **SEM_3_STATUS**, a qualitative variable coded as follows:\n","\n","| Code | Meaning |\n","|---|---|\n","|E |Enrolled |\n","|N |Not Enrolled |\n","|G |Graduated |\n","\n","\n","Let's load the necessary Python libraries to import the data and start to process it for analysis:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d9aac7bb-f404-4e43-ab2e-0be51acb353e","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"Gkngsws3xC2A"},"outputs":[],"source":["import pandas as pd\n","import warnings\n","\n","pd.set_option('display.max_columns', None)\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"8597f1bc-fa06-4b62-9d02-11d7db751c55","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"uWE484OmxC2C"},"source":["Now let's import the **ml_data** data we've curated. Then, by typing the name we assign it, we can scope out the top and bottom 5 rows of the DataFrame and view its basic attributes in detail:"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"FRKkoKEy2Ij2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750278794910,"user_tz":420,"elapsed":18363,"user":{"displayName":"keval patel","userId":"03882503332481059053"}},"outputId":"700d0238-0b05-409e-e0f4-ad4cb90860da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2df1d965-9e91-4410-a895-f5adc652771e","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"M7SR_bKTxC2C","outputId":"02d8e20b-2f75-4f5c-a85e-bd3b2537dc8f","colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"status":"error","timestamp":1750278886108,"user_tz":420,"elapsed":114,"user":{"displayName":"keval patel","userId":"03882503332481059053"}},"collapsed":true},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/projects/Applied-Data-Analytics-For-Higher-Education-Course-2/data/student_academics_data.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-5-1468422157.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/projects/Applied-Data-Analytics-For-Higher-Education-Course-2/data/student_academics_data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/projects/Applied-Data-Analytics-For-Higher-Education-Course-2/data/student_academics_data.csv'"]}],"source":["file_path = '/content/drive/MyDrive/projects/Applied-Data-Analytics-For-Higher-Education-Course-2/data/student_academics_data.csv'\n","\n","df = pd.read_csv(file_path)\n","display(df.head())"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"dd051737-d0b3-4783-a7cb-2170372f40cd","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"yZHlIY2_xC2C"},"source":["<a id=\"2\"></a>\n","## 2 Data Wrangling"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"27dfde7d-8903-4d12-b5af-4a537ea04ccc","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"MD8JVMzWxC2C"},"source":["Data availability is a necessary condition for data analysis, but it is not sufficient. There are a number of modifications we need to make to the data to prepare it for machine learning. The process of preparing the data for exploration and modeling is known as **data wrangling**, and will be performed here.\n","To answer Shontelle's question, we need to build a model using cohorts for which term 3 grade data has already been collected. Thus our response variable will be based on the SEM_3_STATUS variable. Let's dig deeper."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0f13a538-8912-4983-81cd-484321176047","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"KBLcnD64xC2C"},"source":["<a id=\"21\"></a>\n","\n","#### 2.1 Response Variable Distribution"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"74494fd3-5b36-4075-8126-7f8760bb7420","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"VYO537LtxC2C"},"source":["Recall that this DataFrame consists of three cohorts: Fall 2021, Fall 2022 and Fall 2023. The cohort sizes may be identified as follows:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"27765503-4cc0-4a5d-9fc4-fc55b3c501bd","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"rrmKxVIvxC2C","outputId":"a4d7f589-3827-4531-b39a-cbb1cab6fda0","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1750278161381,"user_tz":420,"elapsed":17,"user":{"displayName":"Juan Carlos Apitz","userId":"03950181818081360563"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["COHORT\n","Fall 2022    5363\n","Fall 2019    5170\n","Fall 2018    4954\n","Fall 2020    4910\n","Fall 2021    4866\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>COHORT</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Fall 2022</th>\n","      <td>5363</td>\n","    </tr>\n","    <tr>\n","      <th>Fall 2019</th>\n","      <td>5170</td>\n","    </tr>\n","    <tr>\n","      <th>Fall 2018</th>\n","      <td>4954</td>\n","    </tr>\n","    <tr>\n","      <th>Fall 2020</th>\n","      <td>4910</td>\n","    </tr>\n","    <tr>\n","      <th>Fall 2021</th>\n","      <td>4866</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":19}],"source":["df['COHORT'].value_counts()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c6c4d9a1-d81a-4236-92ad-8401d0dff873","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"7z-JSS8lxC2C"},"source":["The code below groups the retention DataFrame by 'COHORT' and 'SEM_3_STATUS' columns, counts the number of occurrences for each category, and resets the index, renaming the count column to 'COUNTS'.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"58842493-be6f-4f2d-9048-440c00078d35","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"m-G9sDCWxC2D","outputId":"50acb7bc-f9b8-47f1-a03f-87d691dced00","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1750278161708,"user_tz":420,"elapsed":31,"user":{"displayName":"Juan Carlos Apitz","userId":"03950181818081360563"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      COHORT SEM_3_STATUS  COUNTS\n","0  Fall 2018            E    4307\n","1  Fall 2018            N     647\n","2  Fall 2019            E    4583\n","3  Fall 2019            N     587\n","4  Fall 2020            E    4239\n","5  Fall 2020            N     671\n","6  Fall 2021            E    4133\n","7  Fall 2021            N     733\n","8  Fall 2022            E    4540\n","9  Fall 2022            N     823"],"text/html":["\n","  <div id=\"df-b903b621-9ab2-42ac-9050-7094cb6506d6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>COHORT</th>\n","      <th>SEM_3_STATUS</th>\n","      <th>COUNTS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Fall 2018</td>\n","      <td>E</td>\n","      <td>4307</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Fall 2018</td>\n","      <td>N</td>\n","      <td>647</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Fall 2019</td>\n","      <td>E</td>\n","      <td>4583</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Fall 2019</td>\n","      <td>N</td>\n","      <td>587</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Fall 2020</td>\n","      <td>E</td>\n","      <td>4239</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Fall 2020</td>\n","      <td>N</td>\n","      <td>671</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Fall 2021</td>\n","      <td>E</td>\n","      <td>4133</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Fall 2021</td>\n","      <td>N</td>\n","      <td>733</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Fall 2022</td>\n","      <td>E</td>\n","      <td>4540</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Fall 2022</td>\n","      <td>N</td>\n","      <td>823</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b903b621-9ab2-42ac-9050-7094cb6506d6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b903b621-9ab2-42ac-9050-7094cb6506d6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b903b621-9ab2-42ac-9050-7094cb6506d6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-3632f39a-f2fb-4104-a5f9-c0920ae5b8c3\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3632f39a-f2fb-4104-a5f9-c0920ae5b8c3')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-3632f39a-f2fb-4104-a5f9-c0920ae5b8c3 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df[['COHORT', 'SEM_3_STATUS']]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"COHORT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Fall 2019\",\n          \"Fall 2022\",\n          \"Fall 2020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SEM_3_STATUS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"N\",\n          \"E\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"COUNTS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1938,\n        \"min\": 587,\n        \"max\": 4583,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          4540,\n          647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":20}],"source":["df[['COHORT', 'SEM_3_STATUS']].groupby(['COHORT', 'SEM_3_STATUS']).size().reset_index(name='COUNTS')"]},{"cell_type":"markdown","source":["### Data Quality Assurance"],"metadata":{"id":"RzkahKBACjiN"}},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a752ad5b-fb9e-498e-b041-927c0599f65e","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"IZd_Ty9DxC2D"},"source":["We may proceed by investigating data quality issues in our DataFrame that could affect our analysis. These include\n","\n"," - Drop non-informative features\n"," - Missing values in features\n"," - Rare classes in features\n"," - Noninformative features"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"3d505bbe-4bfa-4a44-8520-9409e41764ee","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"QsPnrgUixC2F"},"source":["<a id=\"23\"></a>\n","\n","#### Noninformative features"]},{"cell_type":"markdown","source":["##### Drop unnecessary or redundant columns outside of analysis scope"],"metadata":{"id":"WOCca0IXRa27"}},{"cell_type":"code","source":["df.drop(['HS_GPA', 'SEM_1_STATUS', 'SEM_2_STATUS'], axis=1, inplace=True)"],"metadata":{"id":"1PjVPAx2SkVU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4a345398-7940-4ea8-9523-ef47e882e9a0","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"1Ktgh6--xC2I"},"source":["<a id=\"4\"></a>\n","### Addressing Missingness"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"bba7318a-e601-4bbc-9e63-42c6fc086b24","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"my-WaoALxC2I"},"source":["As mentioned previously, an essential data preprocessing step for modeling in scikit learn is accounting for missingness in our observations. Scikit learn models will not run with missing data, so we need to decide how to deal with it.\n","Let's investigate missingness in our dataset, and use that to determine the most effective way to proceed:"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"fb1e5556-9a73-46ca-87b2-bccdae4a258d","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"6lLKiCuFxC2I"},"source":["To check for missing values in a Pandas DataFrame, we can use the command `df.isnull().sum()`. The output of this command shows a large number of missing values in our data. This is expected, as high school data is not available for many students. While missing data can sometimes be ignored during exploratory data analysis, it must be addressed for predictive modeling using libraries like statsmodels and scikit-learn, which require complete data.\n","\n"]},{"source":["display(df.isnull().sum())"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":680},"id":"SVwh_20TVIqL","executionInfo":{"status":"ok","timestamp":1750278164842,"user_tz":420,"elapsed":15,"user":{"displayName":"Juan Carlos Apitz","userId":"03950181818081360563"}},"outputId":"047218d4-5c36-4a09-e476-7d49015fe2e5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["SID                      0\n","COHORT                   0\n","RACE_ETHNICITY           0\n","GENDER                   0\n","FIRST_GEN_STATUS         0\n","FAMILY_INCOME        20967\n","HS_MATH_GPA            359\n","HS_ENGL_GPA            359\n","COLLEGE                  0\n","UNITS_ATTEMPTED_1      130\n","UNITS_ATTEMPTED_2     1037\n","UNITS_COMPLETED_1        0\n","UNITS_COMPLETED_2      904\n","DFW_UNITS_1              0\n","DFW_UNITS_2            904\n","GPA_1                  130\n","GPA_2                 1037\n","GPA_3                 3067\n","SEM_3_STATUS             0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>SID</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>COHORT</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>RACE_ETHNICITY</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GENDER</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>FIRST_GEN_STATUS</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>FAMILY_INCOME</th>\n","      <td>20967</td>\n","    </tr>\n","    <tr>\n","      <th>HS_MATH_GPA</th>\n","      <td>359</td>\n","    </tr>\n","    <tr>\n","      <th>HS_ENGL_GPA</th>\n","      <td>359</td>\n","    </tr>\n","    <tr>\n","      <th>COLLEGE</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>UNITS_ATTEMPTED_1</th>\n","      <td>130</td>\n","    </tr>\n","    <tr>\n","      <th>UNITS_ATTEMPTED_2</th>\n","      <td>1037</td>\n","    </tr>\n","    <tr>\n","      <th>UNITS_COMPLETED_1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>UNITS_COMPLETED_2</th>\n","      <td>904</td>\n","    </tr>\n","    <tr>\n","      <th>DFW_UNITS_1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>DFW_UNITS_2</th>\n","      <td>904</td>\n","    </tr>\n","    <tr>\n","      <th>GPA_1</th>\n","      <td>130</td>\n","    </tr>\n","    <tr>\n","      <th>GPA_2</th>\n","      <td>1037</td>\n","    </tr>\n","    <tr>\n","      <th>GPA_3</th>\n","      <td>3067</td>\n","    </tr>\n","    <tr>\n","      <th>SEM_3_STATUS</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Before proceeding, we need to decide how to handle these missing values. We have three main options:\n","\n","1.  **Exclude variables with excessive missingness:** Remove entire columns that have missing values above a threshold\n","2.  **Impute values:** Fill in missing values with estimated or plausible values.\n","3.  **Remove observations:** Delete all rows that contain any missing values.\n","\n"],"metadata":{"id":"X2awn9ovAPYN"}},{"cell_type":"markdown","source":["## Addressing Missing Values: Why Imputation Follows Data Splitting\n","\n","Handling missing data is a key step in preparing your dataset for machine learning. Here we identified missing values and dropped columns with over 50% missing data, which impacts how duplicates are found.\n","\n","### Impact of Dropping High Missingness Columns\n","\n","Dropping columns with a high percentage of missing values affects subsequent data cleaning steps, including duplicate detection. If this step were performed *after* splitting the data, the training and testing sets might have different sets of columns dropped based on their individual missingness profiles. This could lead to inconsistencies between the training and testing data, potentially impacting model performance and interpretability. Performing this removal *before* splitting ensures that both the training and testing sets have the same set of features based on the overall data's missingness patterns. This consistent feature set then allows for more reliable duplicate detection based on the remaining, more complete columns across the entire dataset before the split.\n","\n","### Imputation and Data Leakage\n","\n","After handling high missingness and duplicates, remaining missing values need imputation. To prevent **data leakage**, it's vital to impute *after* splitting data into training and testing sets.\n","\n","Data leakage occurs when test set information influences the training process. If imputation values (like means) are calculated using the entire dataset before splitting, information from the test set leaks into the training set.\n","\n","**Imputing After Splitting:**\n","\n","*   Calculate imputation values (e.g., mean) using *only* the training data.\n","*   Fill missing values in the training set using these training-based values.\n","*   Fill missing values in the testing set using the *same* values calculated from the training set.\n","\n","This approach ensures the model learns to handle missing data based only on the training set's patterns, accurately reflecting how it would perform on new, unseen data. Imputing before splitting can lead to an overestimation of model performance on the test set.\n","\n","Therefore, imputing missing values after splitting is crucial for preventing data leakage and getting a realistic measure of your model's ability to generalize."],"metadata":{"id":"fw09RUPmLrsT"}},{"source":["#### ***Exclude variables with excessive missingness***: Identify columns with more than 50% missing values and drop them from the dataframe.\n","\n"],"cell_type":"markdown","metadata":{"id":"BSq8pF09VOYc"}},{"source":["missing_values_count = df.isnull().sum()\n","total_rows = len(df)\n","columns_to_drop = missing_values_count[missing_values_count / total_rows > 0.5].index.tolist()\n","df.drop(columns=columns_to_drop, inplace=True)\n","display(f\"Number of remaining columns: {df.shape[1]}\")\n","display(df.head())"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"_n4A9YZPVOoL","executionInfo":{"status":"ok","timestamp":1750278170240,"user_tz":420,"elapsed":98,"user":{"displayName":"Juan Carlos Apitz","userId":"03950181818081360563"}},"outputId":"51ff1462-f73a-486d-c019-5ae6a131bba2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["'Number of remaining columns: 18'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["         SID     COHORT             RACE_ETHNICITY  GENDER  \\\n","0  UHDOP5522  Fall 2020                      Asian  Female   \n","1  UHE842CU6  Fall 2021  Black or African American  Female   \n","2  UHJFT1JAB  Fall 2018                      Asian  Female   \n","3  UHKF05TAF  Fall 2018                   Hispanic  Female   \n","4  UHKKQ8UY5  Fall 2021                   Hispanic    Male   \n","\n","        FIRST_GEN_STATUS  HS_MATH_GPA  HS_ENGL_GPA                   COLLEGE  \\\n","0  Continuing Generation          3.2        3.400  Visual & Performing Arts   \n","1  Continuing Generation          2.6        3.750  Visual & Performing Arts   \n","2  Continuing Generation          3.4        3.500  Visual & Performing Arts   \n","3       First Generation          3.0        3.375      Letters & Humanities   \n","4  Continuing Generation          2.5        2.625      Letters & Humanities   \n","\n","   UNITS_ATTEMPTED_1  UNITS_ATTEMPTED_2  UNITS_COMPLETED_1  UNITS_COMPLETED_2  \\\n","0               15.0               14.0               15.0               15.0   \n","1               12.0               12.0               12.0               12.0   \n","2               15.0               15.0               15.0               16.0   \n","3               16.0                9.0                7.0                3.0   \n","4               13.0               13.0               13.0               13.0   \n","\n","   DFW_UNITS_1  DFW_UNITS_2     GPA_1     GPA_2  GPA_3 SEM_3_STATUS  \n","0          0.0          0.0  4.000000  3.785714    4.0            E  \n","1          3.0          4.0  3.000000  2.500000    1.5            E  \n","2          0.0          0.0  3.800000  3.600000    3.6            E  \n","3          9.0          9.0  1.562500  1.000000    2.5            E  \n","4          0.0          0.0  3.538462  3.769231    3.4            E  "],"text/html":["\n","  <div id=\"df-0a45dc68-e392-4bde-a775-19186bf7b5db\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SID</th>\n","      <th>COHORT</th>\n","      <th>RACE_ETHNICITY</th>\n","      <th>GENDER</th>\n","      <th>FIRST_GEN_STATUS</th>\n","      <th>HS_MATH_GPA</th>\n","      <th>HS_ENGL_GPA</th>\n","      <th>COLLEGE</th>\n","      <th>UNITS_ATTEMPTED_1</th>\n","      <th>UNITS_ATTEMPTED_2</th>\n","      <th>UNITS_COMPLETED_1</th>\n","      <th>UNITS_COMPLETED_2</th>\n","      <th>DFW_UNITS_1</th>\n","      <th>DFW_UNITS_2</th>\n","      <th>GPA_1</th>\n","      <th>GPA_2</th>\n","      <th>GPA_3</th>\n","      <th>SEM_3_STATUS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>UHDOP5522</td>\n","      <td>Fall 2020</td>\n","      <td>Asian</td>\n","      <td>Female</td>\n","      <td>Continuing Generation</td>\n","      <td>3.2</td>\n","      <td>3.400</td>\n","      <td>Visual &amp; Performing Arts</td>\n","      <td>15.0</td>\n","      <td>14.0</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.000000</td>\n","      <td>3.785714</td>\n","      <td>4.0</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>UHE842CU6</td>\n","      <td>Fall 2021</td>\n","      <td>Black or African American</td>\n","      <td>Female</td>\n","      <td>Continuing Generation</td>\n","      <td>2.6</td>\n","      <td>3.750</td>\n","      <td>Visual &amp; Performing Arts</td>\n","      <td>12.0</td>\n","      <td>12.0</td>\n","      <td>12.0</td>\n","      <td>12.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.000000</td>\n","      <td>2.500000</td>\n","      <td>1.5</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>UHJFT1JAB</td>\n","      <td>Fall 2018</td>\n","      <td>Asian</td>\n","      <td>Female</td>\n","      <td>Continuing Generation</td>\n","      <td>3.4</td>\n","      <td>3.500</td>\n","      <td>Visual &amp; Performing Arts</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>15.0</td>\n","      <td>16.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.800000</td>\n","      <td>3.600000</td>\n","      <td>3.6</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>UHKF05TAF</td>\n","      <td>Fall 2018</td>\n","      <td>Hispanic</td>\n","      <td>Female</td>\n","      <td>First Generation</td>\n","      <td>3.0</td>\n","      <td>3.375</td>\n","      <td>Letters &amp; Humanities</td>\n","      <td>16.0</td>\n","      <td>9.0</td>\n","      <td>7.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>1.562500</td>\n","      <td>1.000000</td>\n","      <td>2.5</td>\n","      <td>E</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>UHKKQ8UY5</td>\n","      <td>Fall 2021</td>\n","      <td>Hispanic</td>\n","      <td>Male</td>\n","      <td>Continuing Generation</td>\n","      <td>2.5</td>\n","      <td>2.625</td>\n","      <td>Letters &amp; Humanities</td>\n","      <td>13.0</td>\n","      <td>13.0</td>\n","      <td>13.0</td>\n","      <td>13.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.538462</td>\n","      <td>3.769231</td>\n","      <td>3.4</td>\n","      <td>E</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a45dc68-e392-4bde-a775-19186bf7b5db')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0a45dc68-e392-4bde-a775-19186bf7b5db button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0a45dc68-e392-4bde-a775-19186bf7b5db');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-af928d17-4d89-4cee-b19b-eb665f0db8e5\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af928d17-4d89-4cee-b19b-eb665f0db8e5')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-af928d17-4d89-4cee-b19b-eb665f0db8e5 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"SID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"UHE842CU6\",\n          \"UHKKQ8UY5\",\n          \"UHJFT1JAB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"COHORT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Fall 2020\",\n          \"Fall 2021\",\n          \"Fall 2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RACE_ETHNICITY\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Asian\",\n          \"Black or African American\",\n          \"Hispanic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GENDER\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FIRST_GEN_STATUS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"First Generation\",\n          \"Continuing Generation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HS_MATH_GPA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3847076812334269,\n        \"min\": 2.5,\n        \"max\": 3.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.6,\n          2.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HS_ENGL_GPA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42108490830235173,\n        \"min\": 2.625,\n        \"max\": 3.75,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.75,\n          2.625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"COLLEGE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Letters & Humanities\",\n          \"Visual & Performing Arts\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNITS_ATTEMPTED_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6431676725154984,\n        \"min\": 12.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          12.0,\n          13.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNITS_ATTEMPTED_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3021728866442674,\n        \"min\": 9.0,\n        \"max\": 15.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          12.0,\n          13.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNITS_COMPLETED_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.286335345030997,\n        \"min\": 7.0,\n        \"max\": 15.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          12.0,\n          13.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNITS_COMPLETED_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.167204273105526,\n        \"min\": 3.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          12.0,\n          13.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DFW_UNITS_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.9115214431215892,\n        \"min\": 0.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DFW_UNITS_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.9749213828703582,\n        \"min\": 0.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPA_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9790302267607689,\n        \"min\": 1.5625,\n        \"max\": 4.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.0,\n          3.5384615384615383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPA_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2036663088337125,\n        \"min\": 1.0,\n        \"max\": 3.7857142857142856,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.5,\n          3.769230769230769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPA_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.002496882788171,\n        \"min\": 1.5,\n        \"max\": 4.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.5,\n          3.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SEM_3_STATUS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"E\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"46a5f94c-f52b-407f-b9b7-e7efa0aa77a0","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"7F5BF5LxxC2D"},"source":["<a id=\"22\"></a>\n","#### 2.2 Rare Classes in Categorical Features"]},{"cell_type":"markdown","source":["Let's take a look at the distribution of values in our qualitative variables. If it turns out that there are some values that are rare, they could cause issues with our downstream data processing. One way to avoid this is to consolidate rare classes into one. Note that consolidating or dropping variables is not a reflection of their importance or relevance to the analysis; instead they highlight one of the limitations of machine learning and the importance of human oversight to create a legitimate representation of the truth."],"metadata":{"id":"l30XdEzgSnYS"}},{"source":["Inspect the unique values and their counts for the categorical columns to identify any anomalies or labels that need fixing.\n","\n"],"cell_type":"markdown","metadata":{"id":"xbg-2WNbVJfA"}},{"source":["categorical_cols = df.select_dtypes(include='object').columns\n","for col in categorical_cols:\n","    display(f\"Value counts for column: {col}\")\n","    display(df[col].value_counts())"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OPmNY1DBVJuv","executionInfo":{"status":"ok","timestamp":1750278172666,"user_tz":420,"elapsed":74,"user":{"displayName":"Juan Carlos Apitz","userId":"03950181818081360563"}},"outputId":"474b6fac-e798-4336-fa08-ab84f13ee910"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["'Value counts for column: SID'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["SID\n","P9CHKVJ7X    2\n","0W430472L    2\n","FS2AVPW1M    2\n","FY9HZPJ60    2\n","MWYLJAF1S    2\n","            ..\n","Z8UOMJIWF    1\n","Z8UOB0XEW    1\n","Z8UITDMUC    1\n","Z8UF1Z7WR    1\n","Z965AERFM    1\n","Name: count, Length: 25198, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>SID</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>P9CHKVJ7X</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>0W430472L</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>FS2AVPW1M</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>FY9HZPJ60</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>MWYLJAF1S</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>Z8UOMJIWF</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Z8UOB0XEW</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Z8UITDMUC</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Z8UF1Z7WR</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Z965AERFM</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>25198 rows  1 columns</p>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'Value counts for column: COHORT'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["COHORT\n","Fall 2022    5363\n","Fall 2019    5170\n","Fall 2018    4954\n","Fall 2020    4910\n","Fall 2021    4866\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>COHORT</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Fall 2022</th>\n","      <td>5363</td>\n","    </tr>\n","    <tr>\n","      <th>Fall 2019</th>\n","      <td>5170</td>\n","    </tr>\n","    <tr>\n","      <th>Fall 2018</th>\n","      <td>4954</td>\n","    </tr>\n","    <tr>\n","      <th>Fall 2020</th>\n","      <td>4910</td>\n","    </tr>\n","    <tr>\n","      <th>Fall 2021</th>\n","      <td>4866</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'Value counts for column: RACE_ETHNICITY'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["RACE_ETHNICITY\n","Hispanic                                     12359\n","Asian                                         5995\n","White                                         3481\n","Two or More Races                             1190\n","Nonresident alien                              925\n","Black or African American                      911\n","Unknown                                        318\n","Native Hawaiian or Other Pacific Islander       61\n","American Indian or Alaska Native                23\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>RACE_ETHNICITY</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Hispanic</th>\n","      <td>12359</td>\n","    </tr>\n","    <tr>\n","      <th>Asian</th>\n","      <td>5995</td>\n","    </tr>\n","    <tr>\n","      <th>White</th>\n","      <td>3481</td>\n","    </tr>\n","    <tr>\n","      <th>Two or More Races</th>\n","      <td>1190</td>\n","    </tr>\n","    <tr>\n","      <th>Nonresident alien</th>\n","      <td>925</td>\n","    </tr>\n","    <tr>\n","      <th>Black or African American</th>\n","      <td>911</td>\n","    </tr>\n","    <tr>\n","      <th>Unknown</th>\n","      <td>318</td>\n","    </tr>\n","    <tr>\n","      <th>Native Hawaiian or Other Pacific Islander</th>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>American Indian or Alaska Native</th>\n","      <td>23</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'Value counts for column: GENDER'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["GENDER\n","Female       15119\n","Male         10014\n","Nonbinary       38\n"," Female         26\n","female          26\n"," Male           20\n","male            20\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>GENDER</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Female</th>\n","      <td>15119</td>\n","    </tr>\n","    <tr>\n","      <th>Male</th>\n","      <td>10014</td>\n","    </tr>\n","    <tr>\n","      <th>Nonbinary</th>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>Female</th>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>female</th>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>Male</th>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>male</th>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'Value counts for column: FIRST_GEN_STATUS'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["FIRST_GEN_STATUS\n","Continuing Generation    15735\n","First Generation          7384\n","Unknown                   2144\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>FIRST_GEN_STATUS</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Continuing Generation</th>\n","      <td>15735</td>\n","    </tr>\n","    <tr>\n","      <th>First Generation</th>\n","      <td>7384</td>\n","    </tr>\n","    <tr>\n","      <th>Unknown</th>\n","      <td>2144</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'Value counts for column: COLLEGE'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["COLLEGE\n","Health & Human Services              4581\n","Engineering & Technology             4051\n","General Studies                      3952\n","Letters & Humanities                 3707\n","Natural and Mathematical Sciences    2868\n","Business Administration              2840\n","Visual & Performing Arts             2752\n","Education & Leadership                512\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>COLLEGE</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Health &amp; Human Services</th>\n","      <td>4581</td>\n","    </tr>\n","    <tr>\n","      <th>Engineering &amp; Technology</th>\n","      <td>4051</td>\n","    </tr>\n","    <tr>\n","      <th>General Studies</th>\n","      <td>3952</td>\n","    </tr>\n","    <tr>\n","      <th>Letters &amp; Humanities</th>\n","      <td>3707</td>\n","    </tr>\n","    <tr>\n","      <th>Natural and Mathematical Sciences</th>\n","      <td>2868</td>\n","    </tr>\n","    <tr>\n","      <th>Business Administration</th>\n","      <td>2840</td>\n","    </tr>\n","    <tr>\n","      <th>Visual &amp; Performing Arts</th>\n","      <td>2752</td>\n","    </tr>\n","    <tr>\n","      <th>Education &amp; Leadership</th>\n","      <td>512</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["'Value counts for column: SEM_3_STATUS'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["SEM_3_STATUS\n","E    21802\n","N     3461\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>SEM_3_STATUS</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>E</th>\n","      <td>21802</td>\n","    </tr>\n","    <tr>\n","      <th>N</th>\n","      <td>3461</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}}]},{"source":["First, inconsistent labels in the 'GENDER' column are fixed by converting all entries to a consistent case and removing leading/trailing spaces. Then, rare categories are combined or eliminated, such as the `Nonbinary` class in the `GENDER` feature. Finally, observing the `RACE_ETHNICITY` feature, it is decided to consolidate the 'Unknown', 'Native Hawaiian or Other Pacific Islander', and 'American Indian or Alaska Native' classes into one new 'Other' class.\n","\n"],"cell_type":"markdown","metadata":{"id":"XvVXW8_LVK0w"}},{"cell_type":"markdown","source":["Fix inconsistent labels in the **GENDER** feature by converting all entries to a consistent case and removing leading/trailing spaces."],"metadata":{"id":"YbpM12Ygg692"}},{"source":["df['GENDER'] = df['GENDER'].str.strip().str.capitalize()\n","display(df['GENDER'].value_counts())"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"id":"VvEyJOSzVLEd","executionInfo":{"status":"ok","timestamp":1750278174342,"user_tz":420,"elapsed":26,"user":{"displayName":"Juan Carlos Apitz","userId":"03950181818081360563"}},"outputId":"529d75f5-7b66-4721-eadd-d93baeb82aba"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["GENDER\n","Female       15171\n","Male         10054\n","Nonbinary       38\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>GENDER</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Female</th>\n","      <td>15171</td>\n","    </tr>\n","    <tr>\n","      <th>Male</th>\n","      <td>10054</td>\n","    </tr>\n","    <tr>\n","      <th>Nonbinary</th>\n","      <td>38</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0e394ad3-5142-41b5-884a-5a14bfba8b5e","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"2z5qMN7TxC2E"},"source":["Drop the rare Non-binary class in **GENDER**:"]},{"cell_type":"code","source":["df = df[df['GENDER'] != 'Non-binary']"],"metadata":{"id":"Fe6uGJkhBejQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For **RACE_ETHNICITY** compbine Unknown, Native Hawaiian or Other Pacific Islander, and American Indian or Alaska Native into the category Other\n"],"metadata":{"id":"_y_Qfgiyh9s8"}},{"cell_type":"code","source":["df['RACE_ETHNICITY'] = df['RACE_ETHNICITY'].replace(['Unknown', 'Native Hawaiian or Other Pacific Islander', 'American Indian or Alaska Native'], 'Other')"],"metadata":{"id":"mXEHjxYshq7M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Eliminating Duplicates: Ensuring Data Integrity for Machine Learning\n","\n","Identifying and removing duplicate rows is a vital part of the data cleaning process in a machine learning workflow. Duplicate data can significantly impact the performance and reliability of your model in several ways, and addressing them early is crucial.\n","\n","Here's why eliminating duplicate rows is necessary:\n","\n","### 1. Skewed Model Training\n","\n","When identical rows are present in your dataset, your machine learning model effectively sees the same information multiple times. This can lead to the model being overly influenced by the patterns present in the duplicated rows. The model might learn to predict based on the repeated instances rather than the underlying, unique patterns in the data. This can result in a model that performs well on the training data (because it has seen those examples repeatedly) but generalizes poorly to new, unseen data that doesn't contain the same duplications.\n","\n","### 2. Inflated Evaluation Metrics\n","\n","Duplicate rows can also artificially inflate your model's evaluation metrics. If duplicate data exists in both your training and testing sets (which can happen if you don't remove them before splitting), the model might correctly predict the outcome for a duplicated test instance simply because it learned that exact instance during training. This gives a false impression of the model's ability to generalize to novel data. Metrics like accuracy, precision, and recall can appear higher than they truly are.\n","\n","### 3. Misleading Data Distribution\n","\n","Duplicate rows distort the true distribution of your data. For example, if a specific type of observation is duplicated many times, it will appear more frequent in the dataset than it is in reality. This can mislead exploratory data analysis and influence decisions about feature engineering or model selection based on an inaccurate understanding of the data's characteristics.\n","\n","### 4. Increased Training Time and Resource Usage\n","\n","While less critical than model performance issues, duplicate rows also add unnecessary complexity to your dataset. Training a model on a larger dataset with duplicates takes more time and computational resources without adding valuable, unique information. Removing duplicates can lead to more efficient training.\n","\n","By eliminating duplicate rows, you ensure that your model learns from a dataset where each observation represents unique information. This leads to a more accurate representation of the data's underlying patterns, prevents the model from being biased by repeated instances, and provides a more reliable evaluation of its performance on unseen data. It's a fundamental step towards building a robust and generalizable machine learning model."],"metadata":{"id":"f8_oEiFIRouJ"}},{"source":["Check for duplicate rows in the DataFrame.\n","\n"],"cell_type":"markdown","metadata":{"id":"kyCSJ6_0VGHk"}},{"source":["df.duplicated().sum()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8vtCSiOVGXT","executionInfo":{"status":"ok","timestamp":1750278185692,"user_tz":420,"elapsed":26,"user":{"displayName":"Juan Carlos Apitz","userId":"03950181818081360563"}},"outputId":"cea5033f-7951-49f8-f549-208fb2a1e9ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["np.int64(65)"]},"metadata":{},"execution_count":28}]},{"source":["Drop duplicate rows from the DataFrame.\n","\n"],"cell_type":"markdown","metadata":{"id":"CBVJ4DxzVHei"}},{"source":["df.drop_duplicates(inplace=True)\n","display(df.duplicated().sum())"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jag7HbYjVHu0","executionInfo":{"status":"ok","timestamp":1750278188846,"user_tz":420,"elapsed":47,"user":{"displayName":"Juan Carlos Apitz","userId":"03950181818081360563"}},"outputId":"c4a5a81d-044e-4caa-a3f1-3cae0f92d133"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["np.int64(0)"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"08e5e51e-225f-4bdd-ad70-3f0d95496198","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"B9oh9V0vxC2G"},"source":["<a id=\"3\"></a>\n","## 3 Data Splitting\n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4581e111-0c14-4e3c-8ade-17c28fb3b1d9","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"PwPV3DNwxC2G"},"source":["As mentioned in *Module 3: Explaining the Machine Learning Cycle Without Hyperparameter Tuning* we observed that a learning algorithm is only useful to the extent that we can confidently apply it to unseen data to make accurate predictions. The ability to generalize is measured by an investigation of model performance on a random sample of the full data called the test set. Before we explore or analyze our data it is imperative that we split it into a training and test set. This step will reintroduce us to Python's machine learning powerhouse, **[scikit learn](https://scikit-learn.org/stable/index.html)**."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"93e12a4b-9067-42a9-9119-faa218e6474a","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"04wAUanYxC2G"},"source":["<a id=\"31\"></a>\n","#### 3.1 Full Data to Training and Testing"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f3591e16-7de0-4725-81fd-d3585bc39d0c","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"q6PTBssOxC2G"},"source":["Data splitting is one of the most important steps of the machine learning cycle. We've all had instructors that, let's just say, provided alot of friendly *guidance* for what material would appear on an exam (they were pretty popular professors). Often this was in the form of a \"practice exam\". This led to a scenario where the exam was for all intents and purposes observed before exam day, and those who could memorize well were likely to achieve the most success. As much as stressed out college students might enjoy it, this arrangement does not facilitate genuine learning, which is demonstrated by the ability to accurately generalize concepts and constructs to new scenarios.  This is why we split data. So that instead of memorizing content and being tested on how well we can repeat it, we are attempting to learn the \"how\" and \"why\" behind the data generating process so that when new data comes from the process, we can legitimately demonstrate a deep level of understanding. Splitting the data into a train set an a test set, and not using the test set at all to learn patterns in the data will enable our model to demonstrate this deeper understanding. Let's load the **train_test_split** module from the scikit learn library and get our study on!"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"7a5c1323-407a-418f-9615-19e719b58e30","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"MHzPw6wkxC2G"},"outputs":[],"source":["#Class for data splitting\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2cc11e13-ee13-4fb5-bb6d-934f9442b64a","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"aJAWgFFxxC2G"},"source":["Figure 1 displays the first step of the data splitting process: identify and isolate the feature matrix (\\\\(X)\\\\) and label vector (\\\\(y)\\\\) in the context of an easy to visualize dataframe. The figure is followed by the code that gets this process started."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5b124515-a8ec-4c7c-9e0a-f6d6ddce5fca","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"K863MQW5xC2H"},"source":["**Figure 1:** Seperating our curated DataFrame into a feature matrix \\\\((X)\\\\) and label vector \\\\((y\\\\)). An example with a DataFrame with 15 observations.\n","\n","\n","![ih](../public/figures/Xy_pic_2-3.png)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"16c11a6f-8b71-4677-8d33-94f8cce14792","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"dMxNVPENxC2H"},"source":["Next, let's create the feature matrix by removing the target and identifier variables."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5259728b-16f9-4b1f-9583-14ee19a0bdff","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"6M5cYEX1xC2H"},"outputs":[],"source":["#Creating the feature matrix\n","X = training.drop(['SID','COHORT','SEM_2_STATUS'],axis=1)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"39c89e64-09d9-41fe-b6aa-68f9411f3c37","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"NzFo4fg2xC2H"},"source":["For the target variable, we need a column in which 1 represents students who leave in semester 3, and 0 represents students who were retained. Thus we need to **one hot encode** the \"NR\" class in our target:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e1d884d9-263f-4ae6-a8e7-a85eb82bc787","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"pwSecDrvxC2H"},"outputs":[],"source":["#The one hot encoding for the NR class\n","y = training['SEM_2_STATUS'].apply(lambda x: 1 if x == 'NR' else 0)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"588cecd5-d167-4277-8796-e31bb8848148","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"YAp0GsFfxC2H"},"source":["The initial split was a vertical one, seperating features from label. We proceed with a horizontal split, randomly holding out a specified percentage of observations for testing.\n","\n","Let's create an 80-20 split of the data for training, and testing on an unlearned hold out set. One of the most useful functions in scikit learn, **[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)** gets the job done in one line of code:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1bd1c750-79a0-4ca5-9276-bfba3f26ac23","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"yv4zFUPVxC2H"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=rms)\n","\n","#The random_state variable makes the code reproducible - everytime we run this code, the same observations will be allocated to the test set."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b288b88c-6476-4c07-b566-3b6d4856598c","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"Mx9ZWSAPxC2H"},"source":["**Figure 2:** An example of an 80%-20% train-test split on a dataframe with 20 observations. Randomly sample 20% * 20 = 4 values to hold out for model testing: Observations 2,6,13 and 19.\n","\n","![ih](https://github.com/ksuaray/IRML---Regression-and-Classification/blob/MLCert-Sketches/MLCert%20Sketches%202/80-20-Xy.png?raw=true)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"28bc209f-bb43-49b3-90d0-3385ddfc8ae1","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"nZMaAUkExC2H"},"source":["From our original 10,280 observations, 20% \\\\(\\times\\\\) 10,280 \\\\(\\approxeq\\\\) 2056 will be reserved for model testing. To prevent *data leakage*, they will not be part of our data exploration or model fitting whatsoever; we don't want to peek at the test before exam day, right?"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"de236d43-2ffd-4fa4-ad68-7e93e8ace16d","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"J1HQebqCxC2H","outputId":"9c9d3e16-1700-41cb-ff6d-403dc395b135"},"outputs":[{"name":"stdout","output_type":"stream","text":["(8196, 13) (2049, 13)\n"]}],"source":["print(X_train.shape,X_test.shape)"]},{"cell_type":"markdown","source":["### 3.2 Cohort-Based Splitting"],"metadata":{"id":"6FHiu0fs3JKF"}},{"cell_type":"markdown","source":["- Imagine you're trying to predict whether students in the **Fall 2022** cohort will drop out  but your model has only seen data from earlier semesters.\n","\n","- This is a **real-world scenario**: using historical data to make future predictions.\n","\n","- Instead of using a random mix of students, we deliberately separate the latest cohort (Fall 2022) to simulate **how well our model performs on new, unseen students**.\n","\n","- This is known as **cohort-based splitting**, and it's a more realistic evaluation when time or group differences matter.\n"],"metadata":{"id":"0ZZx2t6P4PFW"}},{"cell_type":"code","source":["# Let's separate the test set to only include students from 'Fall 2022' cohort\n","df_test_cohort = df[df['COHORT'] == 'Fall 2022'].copy()\n","\n","# The training set will include all students from earlier cohorts\n","df_train_cohort = df[df['COHORT'] != 'Fall 2022'].copy()\n","\n","# Show shapes of both datasets\n","print(f\"Training Data Shape (Cohort-Based): {df_train_cohort.shape}\")\n","print(f\"Testing Data Shape (Fall 2022 Cohort): {df_test_cohort.shape}\")\n"],"metadata":{"id":"ENl4Y3rj4enV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this case, the training set includes all students **except** those in the Fall 2022 cohort. The test set contains **only** Fall 2022 students.\n","\n","This allows us to test how well the model trained on past students performs on a **completely new group**. It's like training a tutor on last year's students and then seeing how well they guide this year's students.\n"],"metadata":{"id":"55H9PYTf4ohV"}},{"cell_type":"code","source":["# Lets preview 3 rows from each set to understand the data better\n","print(\"Training Data Sample (Before Fall 2022):\")\n","display(df_train_cohort.head(3))\n","\n","print(\"\\nTesting Data Sample (Only Fall 2022):\")\n","display(df_test_cohort.head(3))\n"],"metadata":{"id":"AfcGz4f14w7V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.3 Method Comparison"],"metadata":{"id":"bugLOd_5fjSW"}},{"cell_type":"markdown","source":["**Method 1: Random Split (train_test_split)**\n","\n","Pros:\n","\n","- Ensures that both the training and testing sets are representative of the overall data distribution.\n","- Simple to implement and a standard practice in machine learning.\n","- Avoids potential biases that could arise from non-random splits.\n","\n","Cons:\n","\n","- May not be ideal if one needs to evaluate the model's performance on a specific, future cohort.\n","- If there are significant differences between cohorts, a randomly split test set might not reflect real-world performance.\n","\n","**Method 2: Cohort-Based Split (COHORT == 'Fall 2022')**\n","\n","Pros:\n","\n","- Provides a realistic evaluation of how the model would perform on a specific group, such as the most recent cohort.\n","- Allows you to assess the model's ability to generalize to a cohort that may have different characteristics.\n","\n","Cons:\n","\n","- The test set may not be representative of the overall data distribution if the chosen cohort is significantly different.\n","- If the chosen test cohort is significantly different from the training cohorts, the model's performance might appear worse than it actually is.\n","- Reduces the size of the training data, which could impact model performance, especially for smaller datasets.\n","\n","**When to use which method:**\n","\n","- Use random splitting when you want to build a model that generalizes well to new data from the same population.\n","- Use cohort-based splitting when you need to specifically evaluate your model's performance on a particular group or time period."],"metadata":{"id":"EDIkCo2Pf5wJ"}},{"cell_type":"markdown","source":["# 4 Data Imputation"],"metadata":{"id":"x2MfWZYg7UPK"}},{"cell_type":"markdown","source":["\n","\n","After splitting the data into training and testing sets, we need to make sure the datasets are **clean and complete** before we feed them into a machine learning model. Real-world data often contains **missing values**  cells that are empty or labeled as NaN (`Not a Number`). These can cause problems during training because most algorithms cant handle missing values out-of-the-box.\n","\n","Lets walk through how to handle (or \"impute\") these missing values in a smart and consistent way.\n"],"metadata":{"id":"hdFd5Btu7Xrr"}},{"cell_type":"markdown","source":["## 4.1 Identifying Missing Data\n","\n","This code helps us find out which columns in the training data are missing values and how many values are missing in each.\n","Identifying where the missing data exists is the first step before deciding how to fix it.\n"],"metadata":{"id":"OE3ObXfJ8VRT"}},{"cell_type":"code","source":["# Look for columns in df_train that have missing values\n","missing_train = df_train.isnull().sum()\n","cols_with_missing_train = missing_train[missing_train > 0].index\n","display(cols_with_missing_train)\n"],"metadata":{"id":"LIK7mfbN8fwr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Imputing Missing Values in the Training Set\n","\n","- If a column contains numerical data, we fill the missing values using the median. This prevents extreme values (outliers) from skewing the imputation.\n","\n","- If a column contains categorical data (like labels or categories), we fill missing values using the mode (the most common value).\n","\n","We compute these values only from the training set. This is important because using test data during training can introduce bias (known as data leakage)."],"metadata":{"id":"LYRuXgZM8ias"}},{"cell_type":"code","source":["# For each column with missing values in df_train:\n","for col in cols_with_missing_train.index:\n","    if df_train[col].dtype in ['int64', 'float64']:\n","        # For numerical columns, fill missing values with the column's median\n","        df_train[col].fillna(df_train[col].median(), inplace=True)\n","    else:\n","        # For categorical columns, fill missing values with the most frequent value (mode)\n","        df_train[col].fillna(df_train[col].mode()[0], inplace=True)\n"],"metadata":{"id":"DxVI0hRy8vlK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Imputing Missing Values in the Test Set\n","\n","When imputing the test set, we do not calculate new statistics.\n","Instead, we reuse the same median and mode values from the training set. This simulates a real-world deployment, where the model sees only new data but relies on patterns learned from the past."],"metadata":{"id":"_Lsts3Hh8ySc"}},{"cell_type":"code","source":["# Now do the same for df_test, but use training data statistics\n","missing_test = df_test.isnull().sum()\n","cols_with_missing_test = missing_test[missing_test > 0].index\n","\n","for col in cols_with_missing_test.index:\n","    if df_train[col].dtype in ['int64', 'float64']:\n","        df_test[col].fillna(df_train[col].median(), inplace=True)\n","    else:\n","        df_test[col].fillna(df_train[col].mode()[0], inplace=True)\n"],"metadata":{"id":"TIBDBW4Z86ON"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.4 Imputing Missing Values in Cohort-Based Splits"],"metadata":{"id":"VgEC-qJJ_UEr"}},{"cell_type":"markdown","source":["Now we apply the same imputation process to our **cohort-based training and testing datasets**. This ensures both random-split and cohort-split versions of the data are clean and consistent before we proceed.\n","\n","We use the **same function** to maintain consistency and reusability."],"metadata":{"id":"lxrV38ns_Z1z"}},{"cell_type":"code","source":["df_train_cohort, df_test_cohort = impute_missing_values(df_train_cohort, df_test_cohort)\n"],"metadata":{"id":"3vOkdigI_Xqe"},"execution_count":null,"outputs":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"computePreferences":null,"dashboards":[],"environmentMetadata":null,"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"2.3. Get Your Data Machine Learning Ready for Classification: Data Wrangling","widgets":{}},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 [3.10]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}